{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimicking Bertrand Russell's writing style with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import researchpy as rp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "os.chdir('../Book files/books')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import string\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "import keras\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generative Models for Text\n",
    "\n",
    "#### (C) LSTM: Train an LSTM to mimic Russell’s style and thoughts:\n",
    "##### i. Concatenate your text files to create a corpus of Russell’s writings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPP:The Problems of Philosophy\n",
    "# TAM: The Analysis of Mind\n",
    "# MLOE:  Mysticism and Logic and Other Essays\n",
    "# OKEWFSMP: Our Knowledge of the External World as a Field for Scientific Method in Philosophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFiles = [\"TPP.txt\",\"TAM.txt\",\"MLOE.txt\",\"OKEWFSMP.txt\" ]            \n",
    "\n",
    "resultFile = open('corpus.txt', 'w')\n",
    "for fileItem in dataFiles:\n",
    "        with open(fileItem, 'r', errors='ignore') as ff:\n",
    "            for line in ff:\n",
    "                resultFile.write(line)\n",
    "\n",
    "resultFile.close()\n",
    "\n",
    "corpus = open('corpus.txt', 'r').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿CHAPTER I. APPEARANCE AND REALITY\n",
      "\n",
      "Is there any knowledge in the world which is so certain that no\n",
      "reasonable man could doubt it? This question, which at first sight might\n",
      "not seem difficult, is really one of the most difficult that can\n",
      "be asked. When we have realized the obstacles in the way of a\n",
      "straightforward and confident answer, we shall be well launched on the\n",
      "study of philosophy--for philosophy is merely the attempt to answer\n",
      "such ultimate questions, not carelessly and dogmatically, as we do in\n",
      "ordinary life and even in the sciences, but critically, after exploring\n",
      "all that makes such questions puzzling, and after realizing all the\n",
      "vagueness and confusion that underlie our ordinary ideas.\n",
      "\n",
      "In daily life, we assume as certain many things which, on a closer\n",
      "scrutiny, are found to be so full of apparent contradictions that only a\n",
      "great amount of thought enables us to know what it is that we really may\n",
      "believe. In the search for certainty, it is natural to begin with our\n",
      "present\n",
      "1577591\n"
     ]
    }
   ],
   "source": [
    "print(corpus [:1000])\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii. Use a character-level representation for this model by using extended ASCII that has N = 256 characters. Each character will be encoded into a an integer using its ASCII code. Rescale the integers to the range [0, 1], because LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï chapter i appearance and reality is there any knowledge in the world which is so certain that no reasonable man could doubt it this question which at first sight might not seem difficult is really one of the most difficult that can be asked when we have realized the obstacles in the way of a straightforward and confident answer we shall be well launched on the study of philosophy for philosophy is merely the attempt to answer such ultimate questions not carelessly and dogmatically as we do in ordinary life and even in the sciences but critically after exploring all that makes such questions puzzling and after realizing all the vagueness and confusion that underlie our ordinary ideas in daily life we assume as certain many things which on a closer scrutiny are found to be so full of apparent contradictions that only a great amount of thought enables us to know what it is that we really may believe in the search for certainty it is natural to begin with our present experiences and in s\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "text = corpus.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "\n",
    "\n",
    "# lowercasing all the text + removing all the punctuations\n",
    "text = corpus.lower()\n",
    "# words = nltk.word_tokenize(text)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "text = tokenizer.tokenize(text)\n",
    "\n",
    "# print(len(text))\n",
    "text =' '.join(text)\n",
    "print(text [:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing bad_chars_list\n",
    "bad_chars = ['µ', '¼','å', '_','²','½', '³','á', 'å', 'º', '¹', 'ƒ', 'µ', 'î','â', \n",
    "             'ã', 'ï', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '\\n', '_', 'â', '\\xa0','ã', 'î']\n",
    "for i in bad_chars :\n",
    "    text = text.replace(i, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({' ': 273218, 'e': 160450, 't': 123709, 'i': 102032, 'a': 95505, 'o': 93371, 's': 91431, 'n': 89120, 'h': 68627, 'r': 66178, 'l': 47580, 'c': 44913, 'd': 37002, 'u': 34004, 'f': 31151, 'm': 30673, 'p': 26752, 'y': 21720, 'z': 388})\n"
     ]
    }
   ],
   "source": [
    "count = collections.Counter(text)\n",
    "# value = print.pformat(count)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('z', 388),\n",
       " ('y', 21720),\n",
       " ('p', 26752),\n",
       " ('m', 30673),\n",
       " ('f', 31151),\n",
       " ('u', 34004),\n",
       " ('d', 37002),\n",
       " ('c', 44913),\n",
       " ('l', 47580),\n",
       " ('r', 66178),\n",
       " ('h', 68627),\n",
       " ('n', 89120),\n",
       " ('s', 91431),\n",
       " ('o', 93371),\n",
       " ('a', 95505),\n",
       " ('i', 102032),\n",
       " ('t', 123709),\n",
       " ('e', 160450),\n",
       " (' ', 273218)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= list(count.items())\n",
    "# sorted(a, reverse=True)\n",
    "a.sort(key = lambda x: x[1]) \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': 0,\n",
       " 'y': 1,\n",
       " 'p': 2,\n",
       " 'm': 3,\n",
       " 'f': 4,\n",
       " 'u': 5,\n",
       " 'd': 6,\n",
       " 'c': 7,\n",
       " 'l': 8,\n",
       " 'r': 9,\n",
       " 'h': 10,\n",
       " 'n': 11,\n",
       " 's': 12,\n",
       " 'o': 13,\n",
       " 'a': 14,\n",
       " 'i': 15,\n",
       " 't': 16,\n",
       " 'e': 17,\n",
       " ' ': 18}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_char = {}\n",
    "for index, char in enumerate(a):\n",
    "    label_char[char[0]] = index\n",
    "# label_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'z',\n",
       " 1: 'y',\n",
       " 2: 'p',\n",
       " 3: 'm',\n",
       " 4: 'f',\n",
       " 5: 'u',\n",
       " 6: 'd',\n",
       " 7: 'c',\n",
       " 8: 'l',\n",
       " 9: 'r',\n",
       " 10: 'h',\n",
       " 11: 'n',\n",
       " 12: 's',\n",
       " 13: 'o',\n",
       " 14: 'a',\n",
       " 15: 'i',\n",
       " 16: 't',\n",
       " 17: 'e',\n",
       " 18: ' '}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_char = {}\n",
    "for index, char in enumerate(a):\n",
    "    int_char[index] = char[0]\n",
    "# int_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': 122,\n",
       " 'y': 121,\n",
       " 'p': 112,\n",
       " 'm': 109,\n",
       " 'f': 102,\n",
       " 'u': 117,\n",
       " 'd': 100,\n",
       " 'c': 99,\n",
       " 'l': 108,\n",
       " 'r': 114,\n",
       " 'h': 104,\n",
       " 'n': 110,\n",
       " 's': 115,\n",
       " 'o': 111,\n",
       " 'a': 97,\n",
       " 'i': 105,\n",
       " 't': 116,\n",
       " 'e': 101,\n",
       " ' ': 32}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASCII = {}\n",
    "for index, char in enumerate(a):\n",
    "    ASCII[char[0]] = ord(char[0])\n",
    "# ASCII   \n",
    "# len(ASCII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleASCII = {}\n",
    "scaleval= MinMaxScaler().fit_transform(np.array(list(ASCII.values())).reshape(-1, 1))\n",
    "for index in range(len(scaleval)):\n",
    "    scaleASCII[list(ASCII.keys())[index][0]] = scaleval[index][0]\n",
    "\n",
    "# scaleASCII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii. Choose a window size, e.g., W = 100.\n",
    "##### iv. \n",
    "Inputs to the network will be the first W −1 = 99 characters of each sequence,\n",
    "and the output of the network will be the Wth character of the sequence.\n",
    "Basically, we are training the network to predict each character using the 99\n",
    "characters that precede it. Slide the window in strides of S = 1 on the text.\n",
    "For example, if W = 5 and S = 1 and we want to train the network with the\n",
    "sequence ABRACADABRA, The first input to the network will be ABRA\n",
    "and the corresponding output will be C. The second input will be BRAC and\n",
    "the second output will be A, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wsize = 99  # window size -1 \n",
    "\n",
    "X_data= []\n",
    "y_data= []\n",
    "for i in range(0,len(text)- Wsize):\n",
    "    temp =text[i:i + Wsize]\n",
    "    lasttemp = text[i+ Wsize]\n",
    "    X_data.append([scaleASCII[char]for char in temp])\n",
    "    y_data.append(label_char[lasttemp])\n",
    "#     y_data.append(ASCII[lasttemp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437725, 99, 1) (1437725, 19)\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X_data, (len(X_data), Wsize, 1)) #number of patterns\n",
    "y = keras.utils.to_categorical(y_data)\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### v. Note that the output has to be encoded using a one-hot encoding scheme with\n",
    "N = 256 (or less) elements. This means that the network reads integers, but\n",
    "outputs a vector of N = 256 (or less) elements.\n",
    "\n",
    "##### vi.Use a single hidden layer for the LSTM with N = 256 (or less) memory units.\n",
    "##### vii. Use a Softmax output layer to yield a probability prediction for each of the characters between 0 and 1. \n",
    "This is actually a character classification problem\n",
    "with N classes. Choose log loss (cross entropy) as the objective function for\n",
    "the network (research what it means).\n",
    "\n",
    "##### viii. We do not use a test dataset.\n",
    "We are using the whole training dataset to learn the probability of each character in a sequence. We are not seeking for\n",
    "a very accurate model. Instead we are interested in a generalization of the dataset that can mimic the gist of the text.\n",
    "###### ix. Choose a reasonable number of epochs for training, considering your computational power (e.g., 30, although the network will need more epochs to yield a better model).\n",
    "##### x. Use model checkpointing to keep the network weights to determine each time an improvement in loss is observed at the end of the epoch. Find the best set of weights in terms of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Romin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 19)                4883      \n",
      "=================================================================\n",
      "Total params: 269,075\n",
      "Trainable params: 269,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating the model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "# model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile( optimizer='adam', loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Romin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/15\n",
      "    896/1437725 [..............................] - ETA: 2:29:20 - loss: 2.8448"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-c87108f3db84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# checkpoint\n",
    "# filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "filepath=\"weights-improvement1-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X, y, epochs=15, batch_size=128, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xi. Use the network with the best weights to generate 1000 characters, using the\n",
    "following text as initialization of the network:\n",
    "There are those who take mental phenomena naively, just as they\n",
    "would physical phenomena. This school of psychologists tends not to\n",
    "emphasize the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "#generating text via a seed text\n",
    "\n",
    "init_seed_sent = 'there are those who take mental phenomena naively, just as they would physical phenomena. this school of psychologists tends not to emphasize the object.' \n",
    "print(len(init_seed_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "there are those who take mental phenomena naively just as they would physical phenomena this school of psychologists tends not to emphasize the object\n"
     ]
    }
   ],
   "source": [
    "#clean init_text\n",
    "init_seed_sent = init_seed_sent.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "\n",
    "seed = init_seed_sent.lower()\n",
    "seed = tokenizer.tokenize(seed)\n",
    "seed_init =' '.join(seed)\n",
    "print(len(seed_init))\n",
    "print(seed_init)\n",
    "\n",
    "\n",
    "gen = copy.copy(seed_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'there are those who take mental phenomena naively just as they would physical phenomena this school of psychologists tends not to emphasize the object'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = [scaleASCII[char] for char in gen][-99:]\n",
    "for i in range(1000):\n",
    "    XX = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    pred = model.predict(XX, verbose=0)\n",
    "    charIndex = np.argmax(pred)\n",
    "    char = int_char[np.argmax(pred)]\n",
    "    gen += char\n",
    "    pattern.append(scaleASCII[char])\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    \n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### citation:\n",
    "- https://stackoverflow.com/questions/17749058/combine-multiple-text-files-into-one-text-file-using-python\n",
    "- http://www.nltk.org/api/nltk.tokenize.html\n",
    "- https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "- https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "- https://en.wikibooks.org/wiki/Python_Programming/Text#:~:text=To%20get%20the%20ASCII%20code,use%20the%20ord()%20function.&text=To%20get%20the%20character%20encoded,use%20the%20chr()%20function.&text=To%20know%20if%20all%20the,use%20the%20isalnum()%20function.\n",
    "- https://www.geeksforgeeks.org/python-removing-unwanted-characters-from-string/\n",
    "-https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "- https://stackoverflow.com/questions/57081411/i-want-to-create-a-corpus-in-python-from-multiple-text-files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
